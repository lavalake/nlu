作者：知乎用户
链接：https://www.zhihu.com/question/41949741/answer/120941489
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。示中是最后一个）。它跟前面说的那几种序列标注问题的最大的区别是，输出比输入更长（这是表象），而且对应关系不明显（这是这个问题的难点）。在词性标注的例子里，输入某个词时，输出就是该词的词性的概率分布，输出位置和输入位置是一一对应的。在其他几种任务里，即使不是一一对应，也有多对一的关系，例如多个语音帧对应了同一个发音，整个句子对应了一种情感倾向。但这个问题里，哪个输出时间步对应了哪个输入时间步？这一点好像不是特别明确。这个问题解决的办法就是先用一个RNN把输入序列 {A,B,C,D,E} 读一遍，忽略掉它的输出，只是利用它得到 5 个时间步后的隐层状态（隐层神经元个数那么多维的一个向量。这个向量是对输入句子的表示，建模了它的语义）；然后再把这个隐层状态作为每一个时间步的输入（这个例子里一共有 7 个）塞给另一个 RNN，让这个新的RNN输出 {X,Y,Z,A,B,

1、Andrej Karpathy 的博客 The Unreasonable Effectiveness of Recurrent Neural Networks。文章的主要内容是用 char-rnn 学一个语言模型从而生成文本，主要是讲 char-rnn 可以达到的效果而不是算法细节。另一个好处是文章开头点明了 LSTM 的应用是多种多样的，输入和输出的形状也是多种多样的，包括但不限于下图所示的情形：2、Colah 君的文章 Understanding LSTM Networks，对于信息在 LSTM 中的流动解释的很好。多读几遍，记住 LSTM 的公式不是梦。（此人其他博客质量也很高，不妨一读。）3、Recurrent Neural Networks in Tensorflow II。这一系列三篇博客质量都很高，尤其是第二篇和第三篇，里面推荐的阅读文章也都很棒。如果想学习用 tensorflow 实现 rnn，这几篇教程价值无量（tf 官网的教程简直不忍直视，只有 mnist 的教程能看，rnn 的部分根本读不下去）。读完这几篇基本就掌握了用 tf 实现 rnn。另外需要注意的一点是，一定要把一个 RNN 单元理解成这样一个函数：接受一个输入 x_t 和自身之前的状态 s_{t-1}，运算得到一个输出 y_t 和自身的新状态 s_t。（有时候，例如对于 GRU 和 Simple RNN Cell，输出 y_t 和 新状态 s_t 相同，都是隐层状态，但是有必要在逻辑上区分这两者。因为只有对它们做了区分，才好理解怎么把 RNN 单元层叠起来，以及方便阅读 tensorflow 里相关的源代码，理解 tf.scan 的返回值等等。）====================下面是原回答====================>如果这个网络接收输入序列 {A,B,C,D,E}，然后输出 {X,Y,Z,A,B,C,D}，那么这个网络的输入层和输出层的神经元个数应当是多少？(5,7)还是(5,?)还是(?,7)还是(?,?) ？跟5或者7都没关系。你这个例子举得不好，先看一个输入和输出长度相等的例子：词性标注（在AK的图示中就是第四幅）：{I love you} -> {PRONOUN, VERB, PRONOUN}。在这里，输入层有3时间步，每个时间步输入一个词（实际是输入这个词对应的词向量）。可以让模型去学习词向量，也可以用预先训练好的词向量，比如用word2vec来训练然后输入给RNN。词向量的维度你可以自己指定，比如50维，这个维度也就是输入神经元的个数。输入时，第1/2/3个时间步分别输入 I, love, you 的词向量。输出层也有3个时间步，每个时间步输出一个向量，意义跟你要做的任务有关，比如做词性标注一般会输出一个概率分布，表示当前词的每种词性的概率。比如第一个时间步输入是单词 I （的词向量），那么第一个时间步的输出就是 I 属于各种词性的概率。为简单起见，这里我们只考虑两种不同的词性（代词和动词），第一步的输出有可能是 (0.99, 0.01)，表示这个词有 0.99 的可能是一个代词，0.01的可能是一个动词。以此类推，第2和第3个时间步分别输出 love 和 you 可能是什么词性。这个例子里，输入是50维（预先训练好的词向量的维度），输出是2维（每个词属于每种词性的概率），这两个数字跟句子的长度（3）都没什么关系。当然，有时候输出长度 和 输入长度不相等，例如情感分析（输入是一段话，输出是一个标签，问你这段话是积极的还是消极的，在AK的图示中是 many-to-one 那个），或者语音识别（音的帧，输出是文本，但是输出往往要比输入序列要短，比如有几帧发音人没有说话从而输出是空白的等等），这就比上面输入和输出一一对应的例子解释起来要麻烦一些，不过总的来说思想是差不多的。如果你能理解输入输出一一对应时RNN的运行方式，多对少 和 多对一 这两种也不太难理解。至于你提的问题，“输入序列{A,B,C,D,E}，然后输出{X,Y,Z,A,B,C,D}”，这个已经是更高阶的内容了，属于seq2seq learning（在 AK 的图C,D} 这样一个目标序列。其中第一个 RNN 叫 encoder，第二个 RNN 叫 decoder。这种思想很通用，叫 encoder-decoder framework，在机器翻译以及其他很多领域里都输入是很多语有应用，并且越来越流行。
